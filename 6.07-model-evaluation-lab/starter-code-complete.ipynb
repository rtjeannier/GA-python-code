{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison Lab\n",
    "\n",
    "In this lab we will compare the performance of all the models we have learned about so far, using the Titanic dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the data\n",
    "\n",
    "The [titanic dataset](https://www.kaggle.com/c/titanic/data) is one we've talked about a lot. Load in the train data from the assets folder.\n",
    "\n",
    "1. Load the data into a pandas dataframe\n",
    "- Encode the categorical features properly\n",
    "- Separate features from target into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('assets/train.csv')\n",
    "df = pd.get_dummies(df, prefix=['Embarked', 'Sex'], columns=['Embarked', 'Sex'])\n",
    "df['has_cabin'] = df.Cabin.isnull() == False\n",
    "# Replacing nulls with average age, it's better than putting zero\n",
    "df.Age.fillna(np.mean(df.Age), inplace=True)\n",
    "features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Sex_female', 'Sex_male', 'has_cabin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Useful preparation\n",
    "\n",
    "Since we will compare several models, let's write a couple of helper functions.\n",
    "\n",
    "1. Separate X and y between a train and test set, using 30% test set, random state = 42\n",
    "    - make sure that the data is shuffled and stratified\n",
    "2. Define a function called `evaluate_model`, that trains the model on the train set, tests it on the test, calculates the evaluative measures below.\n",
    "  - accuracy score\n",
    "  - confusion matrix\n",
    "  - classification report\n",
    "3. Initialize a global dictionary to store the various models for later retrieval (your dictionary will likely contain the estimator and best score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
    "def evaluate_model(model, X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cr = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(cm)\n",
    "    print(cr)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.a KNN\n",
    "\n",
    "Let's start with `KNeighborsClassifier`.\n",
    "\n",
    "1. Initialize a KNN model\n",
    "- Evaluate its performance with the function you previously defined\n",
    "- Find the optimal value of parameter K using grid search\n",
    "    - Be careful on how you perform the cross validation in the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[147  35]\n",
      " [ 54  59]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.81      0.77       182\n",
      "          1       0.63      0.52      0.57       113\n",
      "\n",
      "avg / total       0.69      0.70      0.69       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "result = evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "params = {'n_neighbors': list(range(2,60))}\n",
    "\n",
    "gs = GridSearchCV(KNeighborsClassifier(),\n",
    "                     params, n_jobs=3,\n",
    "                     cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=3,\n",
       "       param_grid={'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 10}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.738255033557047"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.b Bagging + KNN\n",
    "\n",
    "Now that we have found the optimal K, let's wrap `KNeighborsClassifier` in a BaggingClassifier and see if the score improves.\n",
    "\n",
    "1. Wrap the KNN model in a Bagging Classifier\n",
    "- Evaluate performance\n",
    "- Do a grid search only on the bagging classifier parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagKnn = BaggingClassifier(KNeighborsClassifier())\n",
    "bag_params = {'n_estimators': [10, 20],\n",
    "                  'max_samples': [0.5, 1.0],\n",
    "                  'max_features': [0.5, 1.0],\n",
    "                  'bootstrap_features': [True, False]}\n",
    "\n",
    "gs = GridSearchCV(bagKnn,\n",
    "                     bag_params, n_jobs=3,\n",
    "                     cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[142  40]\n",
      " [ 59  54]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.78      0.74       182\n",
      "          1       0.57      0.48      0.52       113\n",
      "\n",
      "avg / total       0.66      0.66      0.66       295\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.66440677966101691"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(baggingknn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=3,\n",
       "       param_grid={'n_estimators': [10, 20], 'max_samples': [0.5, 1.0], 'max_features': [0.5, 1.0], 'bootstrap_features': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap_features': True,\n",
       " 'max_features': 0.5,\n",
       " 'max_samples': 0.5,\n",
       " 'n_estimators': 10}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8120805369127517"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression\n",
    "\n",
    "Let's see if logistic regression performs better.\n",
    "\n",
    "1. Initialize LR and test on Train/Test set\n",
    "- Find optimal parameters with Grid Search\n",
    "- See if Bagging improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[154  28]\n",
      " [ 31  82]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.85      0.84       182\n",
      "          1       0.75      0.73      0.74       113\n",
      "\n",
      "avg / total       0.80      0.80      0.80       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "model_dict['logreg'] = {'model': lr,\n",
    "                    'score': evaluate_model(lr)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'penalty': 'l1'}\n",
      "0.7957351290684624\n",
      "[[153  29]\n",
      " [ 30  83]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.84      0.84       182\n",
      "          1       0.74      0.73      0.74       113\n",
      "\n",
      "avg / total       0.80      0.80      0.80       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "          'penalty': ['l1', 'l2']}\n",
    "\n",
    "gslr = GridSearchCV(lr,\n",
    "                    params, n_jobs=-1,\n",
    "                    cv=5)\n",
    "\n",
    "gslr.fit(X, y)\n",
    "\n",
    "print(gslr.best_params_)\n",
    "print(gslr.best_score_)\n",
    "\n",
    "model_dict['gslr'] = {'model': gslr.best_estimator_,\n",
    "                             'score': evaluate_model(gslr.best_estimator_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap_features': False, 'max_features': 0.5, 'max_samples': 1.0, 'n_estimators': 20}\n",
      "0.7968574635241302\n",
      "[[166  16]\n",
      " [ 39  74]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.91      0.86       182\n",
      "          1       0.82      0.65      0.73       113\n",
      "\n",
      "avg / total       0.81      0.81      0.81       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_bag_log = GridSearchCV(BaggingClassifier(model_dict['gslr']['model']),\n",
    "                           bag_params, n_jobs=-1,\n",
    "                           cv=5)\n",
    "\n",
    "gs_bag_log.fit(X, y)\n",
    "\n",
    "print(gs_bag_log.best_params_)\n",
    "print(gs_bag_log.best_score_)\n",
    "\n",
    "model_dict['gs_bag_log'] = {'model': gs_bag_log.best_estimator_,\n",
    "                             'score': evaluate_model(gs_bag_log.best_estimator_)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Decision Trees\n",
    "\n",
    "Let's see if Decision Trees perform better.\n",
    "\n",
    "1. Initialize DT and test on Train/Test set\n",
    "- Find optimal parameters with Grid Search\n",
    "- See if Bagging improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[156  26]\n",
      " [ 40  73]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.86      0.83       182\n",
      "          1       0.74      0.65      0.69       113\n",
      "\n",
      "avg / total       0.77      0.78      0.77       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "model_dict['dt'] = {'model': dt,\n",
    "                    'score': evaluate_model(dt)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'splitter': 'random'}\n",
      "0.8226711560044894\n",
      "[[162  20]\n",
      " [ 39  74]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.89      0.85       182\n",
      "          1       0.79      0.65      0.71       113\n",
      "\n",
      "avg / total       0.80      0.80      0.80       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'criterion': ['gini', 'entropy'],\n",
    "          'splitter': ['best', 'random'],\n",
    "          'max_depth': [None, 5, 10],\n",
    "          'min_samples_split': [2, 5],\n",
    "          'min_samples_leaf': [1, 2, 3]}\n",
    "\n",
    "gs_dt = GridSearchCV(DecisionTreeClassifier(),\n",
    "                           params, n_jobs=-1,\n",
    "                           cv=5)\n",
    "\n",
    "gs_dt.fit(X, y)\n",
    "\n",
    "print(gs_dt.best_params_)\n",
    "print(gs_dt.best_score_)\n",
    "\n",
    "model_dict['gs_dt'] = {'model': gs_dt.best_estimator_,\n",
    "                             'score': evaluate_model(gs_dt.best_estimator_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap_features': True, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 20}\n",
      "0.8226711560044894\n",
      "[[166  16]\n",
      " [ 46  67]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.91      0.84       182\n",
      "          1       0.81      0.59      0.68       113\n",
      "\n",
      "avg / total       0.79      0.79      0.78       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gsbaggingdt = GridSearchCV(BaggingClassifier(model_dict['gs_dt']['model']),\n",
    "                           bag_params, n_jobs=-1,\n",
    "                           cv=5)\n",
    "\n",
    "gsbaggingdt.fit(X, y)\n",
    "\n",
    "print(gsbaggingdt.best_params_)\n",
    "print(gsbaggingdt.best_score_)\n",
    "\n",
    "model_dict['gsbaggingdt'] = {'model': gsbaggingdt.best_estimator_,\n",
    "                             'score': evaluate_model(gsbaggingdt.best_estimator_)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Forest & Extra Trees\n",
    "\n",
    "Let's see if Random Forest and Extra Trees perform better.\n",
    "\n",
    "1. Initialize RF and ET and test on Train/Test set\n",
    "- Find optimal parameters with Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[160  22]\n",
      " [ 41  72]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.88      0.84       182\n",
      "          1       0.77      0.64      0.70       113\n",
      "\n",
      "avg / total       0.78      0.79      0.78       295\n",
      "\n",
      "[[152  30]\n",
      " [ 42  71]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.84      0.81       182\n",
      "          1       0.70      0.63      0.66       113\n",
      "\n",
      "avg / total       0.75      0.76      0.75       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "model_dict['rf'] = {'model': rf,\n",
    "                    'score': evaluate_model(rf)}\n",
    "\n",
    "\n",
    "\n",
    "et = ExtraTreesClassifier()\n",
    "model_dict['et'] = {'model': et,\n",
    "                    'score': evaluate_model(et)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "0.8282828282828283\n",
      "[[158  24]\n",
      " [ 39  74]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.87      0.83       182\n",
      "          1       0.76      0.65      0.70       113\n",
      "\n",
      "avg / total       0.78      0.79      0.78       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators':[3, 5, 10, 50],\n",
    "          'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': [None, 3, 5],\n",
    "          'min_samples_split': [2,5],\n",
    "          'class_weight':[None, 'balanced']}\n",
    "\n",
    "\n",
    "gsrf = GridSearchCV(RandomForestClassifier(n_jobs=-1),\n",
    "                    params, n_jobs=-1,\n",
    "                    cv=5)\n",
    "\n",
    "gsrf.fit(X, y)\n",
    "print(gsrf.best_params_)\n",
    "print(gsrf.best_score_)\n",
    "\n",
    "model_dict['gsrf'] = {'model': gsrf.best_estimator_,\n",
    "                      'score': evaluate_model(gsrf.best_estimator_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "0.8249158249158249\n",
      "[[166  16]\n",
      " [ 41  72]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.91      0.85       182\n",
      "          1       0.82      0.64      0.72       113\n",
      "\n",
      "avg / total       0.81      0.81      0.80       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gset = GridSearchCV(RandomForestClassifier(n_jobs=-1),\n",
    "                    params, n_jobs=-1,\n",
    "                    cv=5)\n",
    "\n",
    "gset.fit(X, y)\n",
    "print(gset.best_params_)\n",
    "print(gset.best_score_)\n",
    "\n",
    "model_dict['gset'] = {'model': gset.best_estimator_,\n",
    "                      'score': evaluate_model(gset.best_estimator_)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model comparison\n",
    "\n",
    "Let's compare the scores of the various models.\n",
    "\n",
    "1. Do a bar chart of the scores of the best models. Who's the winner on the train/test split?\n",
    "- Re-test all the models using a 3 fold stratified shuffled cross validation\n",
    "- Do a bar chart with errorbars of the cross validation average scores. is the winner the same?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.776271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>0.755932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gs_bag_log</th>\n",
       "      <td>(LogisticRegression(C=1.0, class_weight=None, ...</td>\n",
       "      <td>0.813559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gs_dt</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gsbaggingdt</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.789831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gset</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.80678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gslr</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gsrf</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.786441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.786441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         model     score\n",
       "dt           DecisionTreeClassifier(class_weight=None, crit...  0.776271\n",
       "et           (ExtraTreeClassifier(class_weight=None, criter...  0.755932\n",
       "gs_bag_log   (LogisticRegression(C=1.0, class_weight=None, ...  0.813559\n",
       "gs_dt        DecisionTreeClassifier(class_weight=None, crit...       0.8\n",
       "gsbaggingdt  (DecisionTreeClassifier(class_weight=None, cri...  0.789831\n",
       "gset         (DecisionTreeClassifier(class_weight=None, cri...   0.80678\n",
       "gslr         LogisticRegression(C=1.0, class_weight=None, d...       0.8\n",
       "gsrf         (DecisionTreeClassifier(class_weight=None, cri...  0.786441\n",
       "logreg       LogisticRegression(C=1.0, class_weight=None, d...       0.8\n",
       "rf           (DecisionTreeClassifier(class_weight=None, cri...  0.786441"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gs_bag_log</th>\n",
       "      <td>(LogisticRegression(C=1.0, class_weight=None, ...</td>\n",
       "      <td>0.813559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gset</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.80678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gs_dt</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gslr</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gsbaggingdt</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.789831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gsrf</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.786441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.786441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.776271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>0.755932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         model     score\n",
       "gs_bag_log   (LogisticRegression(C=1.0, class_weight=None, ...  0.813559\n",
       "gset         (DecisionTreeClassifier(class_weight=None, cri...   0.80678\n",
       "gs_dt        DecisionTreeClassifier(class_weight=None, crit...       0.8\n",
       "gslr         LogisticRegression(C=1.0, class_weight=None, d...       0.8\n",
       "logreg       LogisticRegression(C=1.0, class_weight=None, d...       0.8\n",
       "gsbaggingdt  (DecisionTreeClassifier(class_weight=None, cri...  0.789831\n",
       "gsrf         (DecisionTreeClassifier(class_weight=None, cri...  0.786441\n",
       "rf           (DecisionTreeClassifier(class_weight=None, cri...  0.786441\n",
       "dt           DecisionTreeClassifier(class_weight=None, crit...  0.776271\n",
       "et           (ExtraTreeClassifier(class_weight=None, criter...  0.755932"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAExCAYAAACHweKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niBzqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7eff48c88898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = pd.DataFrame(model_dict).transpose()\n",
    "scores = scores.sort_values('score', ascending=False)\n",
    "scores.plot(kind='bar')\n",
    "plt.ylim(0.5, 1)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "scores.dropna(inplace=True)\n",
    "def cross_validator(df):\n",
    "    df['new_score'] = 0.\n",
    "    df['std'] = 0.\n",
    "    for (i,m) in enumerate(df.model):\n",
    "        scores = cross_val_score(m, X_test, y_test,\n",
    "                                 cv=StratifiedKFold(y_test, shuffle=True),\n",
    "                                 n_jobs=-1)\n",
    "        score = scores.mean()\n",
    "        s = scores.std()\n",
    "        \n",
    "        df.set_value(df.index[i], 'new_score', score)\n",
    "        df.set_value(index=df.index[i], col='std', value=s)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>new_score</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gs_bag_log</th>\n",
       "      <td>(LogisticRegression(C=1.0, class_weight=None, ...</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.813357</td>\n",
       "      <td>0.032523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gset</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.80678</td>\n",
       "      <td>0.796661</td>\n",
       "      <td>0.037487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gs_dt</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.749245</td>\n",
       "      <td>0.015687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gslr</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.799681</td>\n",
       "      <td>0.056276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.806692</td>\n",
       "      <td>0.015361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gsbaggingdt</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.789831</td>\n",
       "      <td>0.786490</td>\n",
       "      <td>0.006620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gsrf</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.786441</td>\n",
       "      <td>0.790066</td>\n",
       "      <td>0.024864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.786441</td>\n",
       "      <td>0.780034</td>\n",
       "      <td>0.044029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.776271</td>\n",
       "      <td>0.725468</td>\n",
       "      <td>0.029229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>0.755932</td>\n",
       "      <td>0.745600</td>\n",
       "      <td>0.023641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         model     score  \\\n",
       "gs_bag_log   (LogisticRegression(C=1.0, class_weight=None, ...  0.813559   \n",
       "gset         (DecisionTreeClassifier(class_weight=None, cri...   0.80678   \n",
       "gs_dt        DecisionTreeClassifier(class_weight=None, crit...       0.8   \n",
       "gslr         LogisticRegression(C=1.0, class_weight=None, d...       0.8   \n",
       "logreg       LogisticRegression(C=1.0, class_weight=None, d...       0.8   \n",
       "gsbaggingdt  (DecisionTreeClassifier(class_weight=None, cri...  0.789831   \n",
       "gsrf         (DecisionTreeClassifier(class_weight=None, cri...  0.786441   \n",
       "rf           (DecisionTreeClassifier(class_weight=None, cri...  0.786441   \n",
       "dt           DecisionTreeClassifier(class_weight=None, crit...  0.776271   \n",
       "et           (ExtraTreeClassifier(class_weight=None, criter...  0.755932   \n",
       "\n",
       "             new_score       std  \n",
       "gs_bag_log    0.813357  0.032523  \n",
       "gset          0.796661  0.037487  \n",
       "gs_dt         0.749245  0.015687  \n",
       "gslr          0.799681  0.056276  \n",
       "logreg        0.806692  0.015361  \n",
       "gsbaggingdt   0.786490  0.006620  \n",
       "gsrf          0.790066  0.024864  \n",
       "rf            0.780034  0.044029  \n",
       "dt            0.725468  0.029229  \n",
       "et            0.745600  0.023641  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validator(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>new_score</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gs_bag_log</th>\n",
       "      <td>(LogisticRegression(C=1.0, class_weight=None, ...</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.813357</td>\n",
       "      <td>0.032523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gset</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.80678</td>\n",
       "      <td>0.796661</td>\n",
       "      <td>0.037487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gs_dt</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.749245</td>\n",
       "      <td>0.015687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gslr</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.799681</td>\n",
       "      <td>0.056276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.806692</td>\n",
       "      <td>0.015361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gsbaggingdt</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.789831</td>\n",
       "      <td>0.786490</td>\n",
       "      <td>0.006620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gsrf</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.786441</td>\n",
       "      <td>0.790066</td>\n",
       "      <td>0.024864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.786441</td>\n",
       "      <td>0.780034</td>\n",
       "      <td>0.044029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.776271</td>\n",
       "      <td>0.725468</td>\n",
       "      <td>0.029229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>0.755932</td>\n",
       "      <td>0.745600</td>\n",
       "      <td>0.023641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         model     score  \\\n",
       "gs_bag_log   (LogisticRegression(C=1.0, class_weight=None, ...  0.813559   \n",
       "gset         (DecisionTreeClassifier(class_weight=None, cri...   0.80678   \n",
       "gs_dt        DecisionTreeClassifier(class_weight=None, crit...       0.8   \n",
       "gslr         LogisticRegression(C=1.0, class_weight=None, d...       0.8   \n",
       "logreg       LogisticRegression(C=1.0, class_weight=None, d...       0.8   \n",
       "gsbaggingdt  (DecisionTreeClassifier(class_weight=None, cri...  0.789831   \n",
       "gsrf         (DecisionTreeClassifier(class_weight=None, cri...  0.786441   \n",
       "rf           (DecisionTreeClassifier(class_weight=None, cri...  0.786441   \n",
       "dt           DecisionTreeClassifier(class_weight=None, crit...  0.776271   \n",
       "et           (ExtraTreeClassifier(class_weight=None, criter...  0.755932   \n",
       "\n",
       "             new_score       std  \n",
       "gs_bag_log    0.813357  0.032523  \n",
       "gset          0.796661  0.037487  \n",
       "gs_dt         0.749245  0.015687  \n",
       "gslr          0.799681  0.056276  \n",
       "logreg        0.806692  0.015361  \n",
       "gsbaggingdt   0.786490  0.006620  \n",
       "gsrf          0.790066  0.024864  \n",
       "rf            0.780034  0.044029  \n",
       "dt            0.725468  0.029229  \n",
       "et            0.745600  0.023641  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAExCAYAAACTeL4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7eff4aac7128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(range(0,len(scores)), scores.new_score,\n",
    "                yerr=scores['std'],\n",
    "                tick_label=scores.index\n",
    "               )\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "plt.xticks(rotation=70)\n",
    "plt.ylim(0.6, 1.1)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>new_score</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gs_bag_log</th>\n",
       "      <td>(LogisticRegression(C=1.0, class_weight=None, ...</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gset</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.80678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gs_dt</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gslr</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gsbaggingdt</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.789831</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gsrf</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.786441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>0.786441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.776271</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>0.755932</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         model     score  \\\n",
       "gs_bag_log   (LogisticRegression(C=1.0, class_weight=None, ...  0.813559   \n",
       "gset         (DecisionTreeClassifier(class_weight=None, cri...   0.80678   \n",
       "gs_dt        DecisionTreeClassifier(class_weight=None, crit...       0.8   \n",
       "gslr         LogisticRegression(C=1.0, class_weight=None, d...       0.8   \n",
       "logreg       LogisticRegression(C=1.0, class_weight=None, d...       0.8   \n",
       "gsbaggingdt  (DecisionTreeClassifier(class_weight=None, cri...  0.789831   \n",
       "gsrf         (DecisionTreeClassifier(class_weight=None, cri...  0.786441   \n",
       "rf           (DecisionTreeClassifier(class_weight=None, cri...  0.786441   \n",
       "dt           DecisionTreeClassifier(class_weight=None, crit...  0.776271   \n",
       "et           (ExtraTreeClassifier(class_weight=None, criter...  0.755932   \n",
       "\n",
       "             new_score  std  \n",
       "gs_bag_log           0    0  \n",
       "gset                 0    0  \n",
       "gs_dt                0    0  \n",
       "gslr                 0    0  \n",
       "logreg               0    0  \n",
       "gsbaggingdt          0    0  \n",
       "gsrf                 0    0  \n",
       "rf                   0    0  \n",
       "dt                   1    0  \n",
       "et                   0    0  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "We have encoded the data using a map that preserves the scale.\n",
    "Would our results have changed if we had encoded the categorical data using `pd.get_dummies` or `OneHotEncoder`  to encode them as binary variables instead?\n",
    "\n",
    "1. Repeat the analysis for this scenario. Is it better?\n",
    "- Experiment with other models or other parameters, can you beat your classmates' best score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I already used pd.get dummies and i got a decent score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
