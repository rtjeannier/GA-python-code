{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Beautiful Soup\n",
    "\n",
    "We've covered APIs, but what happens when the information we want to get from the internet isn't provided for us already? We can use webscraping to collect it directly from the HTML code on each webpage.\n",
    "\n",
    "\n",
    "## What is web scraping?\n",
    "- Extracting information from websites (simulates a human copying and pasting)\n",
    "- Based on finding patterns in website code (usually HTML)\n",
    "\n",
    "\n",
    "## What are best practices for web scraping?\n",
    "- Scraping too many pages too fast can get your IP address blocked\n",
    "- Pay attention to the robots exclusion standard (robots.txt)\n",
    "- Let's look at http://www.facebook.com/robots.txt\n",
    "- Any other sites we should check out?\n",
    "\n",
    "\n",
    "\n",
    "## What is HTML?\n",
    "- Code interpreted by a web browser to produce (\"render\") a web page\n",
    "- Let's look at some example HTML - twitter\n",
    "- Introduce google's inspect tool\n",
    "- What can you tell me about the language?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML code can get complicated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('http://www.openbookproject.net/tutorials/getdown/css/images/lesson4/HTMLDOMTree.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fortunately, Chrome has some great developer tools that let us look at the structure of pages without needing to read or understand HTML\n",
    "\n",
    "## How to view HTML code:\n",
    "- To view the entire page: \"View Source\" or \"View Page Source\" or \"Show Page Source\"\n",
    "- To view a specific part: \"Inspect Element\"\n",
    "- Safari users: Safari menu, Preferences, Advanced, Show Develop menu in menu bar\n",
    "- Let's try it out on twitter.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I webscrape?\n",
    "\n",
    "We will be using two new libraries for our webscraping:\n",
    "- **requests** - lets us acquire the HTML code in python, like a web browser would\n",
    "- **BeautifulSoup** - allows us to interact with the HTML efficiently and easily\n",
    "\n",
    "Webscraping with Python can be broken down into a few simple steps. First we need is to access and then 'download' the page that we want to scrape.\n",
    "\n",
    "We want to scrape [this example site](http://econpy.pythonanywhere.com/ex/001.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html = requests.get('http://econpy.pythonanywhere.com/ex/001.html')\n",
    "#Can someone explain what this is doing? What does the html variable now contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert HTML into a structured Soup object\n",
    "from bs4 import BeautifulSoup\n",
    "b = BeautifulSoup(html.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#what does b look like?\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can make it prettier:\n",
    "\n",
    "print b.prettify()\n",
    "\n",
    "# This looks slightly better, but it's still pretty interpretable. How could I find the item I'm looking for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding items in the site\n",
    "\n",
    "Now that we have the website text saved as a beautiful soup object, we can use bs4 functions to find things on the page for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 'find' method returns the first matching Tag (and everything inside of it)\n",
    "print b.find(name='body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# .text will return the text without the extra tags\n",
    "print b.find(name='body').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "findall will return all matching tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print b.find_all('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b.find_all('div', title='buyer-name')\n",
    "# beautiful soup will let us choose specific elements within div tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-075f659847e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#We can use for loops to select just the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'buyer-name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "#We can use for loops to select just the text\n",
    "for i in b.find_all('div', title='buyer-name'):\n",
    "    print i.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now I have a list of all names on the page\n",
    "# What if I wanted a list of the prices?\n",
    "for i in b.find_all('span'):\n",
    "    print i.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pair practice:\n",
    "# Group work - \n",
    "# build a function that uses the statements above creates a dictionary that pairs the names with prices:\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
